v
# Créer un endpoint avec plumber
#* @post /predict
#* @param input Le texte d'entrée pour les prédictions
predict_function <- function(req) {
# recueillir les données depuis le corps de la requête
data <- jsonlite::fromJSON(req$postBody)
# prédiction avec le modèle
prediction <- vetiver_predict(v, data)
# Retourne la prédiction
return(prediction)
}
pr <- plumb("C:/Users/Degbey Kayeon/Downloads/zWTIOyzKTSG0w5jU5Io_Nw_15c1635f70334a3a9d4b1ec2132e14f1_stroke-prediction/api.R") # Spécifiez le chemin vers le fichier api.R
install.packages("plumber")
library(plumber)
v <- vetiver_model(final_fit_rf, "Random Forest")
v
# Créer un endpoint avec plumber
#* @post /predict
#* @param input Le texte d'entrée pour les prédictions
predict_function <- function(req) {
# recueillir les données depuis le corps de la requête
data <- jsonlite::fromJSON(req$postBody)
# prédiction avec le modèle
prediction <- vetiver_predict(v, data)
# Retourne la prédiction
return(prediction)
}
pr <- plumb("C:/Users/Degbey Kayeon/Downloads/zWTIOyzKTSG0w5jU5Io_Nw_15c1635f70334a3a9d4b1ec2132e14f1_stroke-prediction/api.R") # Spécifiez le chemin vers le fichier api.R
pr$run(port = 8000)
install.packages("tidymodels")
install.packages("tidyverse")
install.packages("corrplot")
install.packages("caret")
install.packages("smotefamily")
install.packages(skimr)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(tidymodels)
library(mice)
library(caret)
library(smotefamily)
library(corrplot)
library(rsample)
# define the filename
filename <- "C:/Users/healthcare-dataset-stroke-data.csv"
# load the CSV file from the local directory
dataset <- read.csv(filename, header=TRUE, sep = ";")
dataset
print("
----------------------------descrption de donnees----------------------------------------------
")
summary(dataset)
print("
----------------------------Type de donnees----------------------------------------------
")
sapply(dataset,class)
print("
--------------------------------------------------------------------------
")
print(unique(dataset$gender))
print(unique(dataset$smoking_status))
ggplot(dataset) +
geom_histogram(aes(x = avg_glucose_level))
data_prep <- dataset
# Convertir la variable char en num
data_prep$bmi <- as.numeric(data_prep$bmi)
#mutation de variables
data_prep <- data_prep%>%
mutate(smoking_status = if_else(tolower(smoking_status) == "formerly smoked",
"smokes",
if_else(tolower(smoking_status) == "unknown",
NA_character_,
smoking_status)))
data_prep
#suppression de variables
data_prep1 <- subset(data_prep, gender != "Other")
data_prep1
print(unique(data_prep1$gender))
print(unique(data_prep1$smoking_status))
# Résumé des valeurs manquantes
md.pattern(data_prep1)
data_prep1
#imputation de la moyenne aux valeurs manquante BMI
data_prep1$bmi <- ifelse(is.na(data_prep1$bmi),
mean(data_prep1$bmi, na.rm = TRUE),
data_prep1$bmi)
data_prep1 <- data_prep1 %>%
mutate(bmi = round(bmi, 1))
#stroke_recipe <- recipes::recipe(stroke ~. , data = data_prep1)%>%
#step_dummy(all_nominal(), -all_outcomes()) %>%
#step_normalize(all_numeric())
#step_impute_knn(all_predictors())
#suppression des autres valeurs manquante
data_prep2<- na.omit(data_prep1)
print(data_prep2)
#stroke_recipe
#imputation de la moyenne aux valeurs manquante BMI
data_prep1$bmi <- ifelse(is.na(data_prep1$bmi),
mean(data_prep1$bmi, na.rm = TRUE),
data_prep1$bmi)
data_prep1 <- data_prep1 %>%
mutate(bmi = round(bmi, 1))
#stroke_recipe <- recipes::recipe(stroke ~. , data = data_prep1)%>%
#step_dummy(all_nominal(), -all_outcomes()) %>%
#step_normalize(all_numeric())
#step_impute_knn(all_predictors())
#suppression des autres valeurs manquante
data_prep2<- na.omit(data_prep1)
print(data_prep2)
#stroke_recipe
ggplot(data_prep2)+
geom_histogram(aes(x=bmi))
data_numeric <- data_prep2[sapply(data_prep2, is.numeric)]
data_numeric
# Calculer la matrice de corrélation
cor_matrix <- cor(data_numeric, use = "complete.obs")
corrplot(cor_matrix, method = "color", type = "upper", tl.col = "black", tl.srt = 45)
#chargement des variables  numeriques
data_numeric <- data_prep2[sapply(data_prep2, is.numeric)]
# Calculer la matrice de corrélation
cor_matrix <- cor(data_numeric, use = "complete.obs")
corrplot(cor_matrix, method = "color", type = "upper", tl.col = "black", tl.srt = 45)
# summarize the class distribution
percentage <- prop.table(table(data_prep2$stroke)) * 100
cbind(freq=table(data_prep2$stroke), percentage=percentage)
# Resumer la distribution de classz
percentage <- prop.table(table(data_prep2$stroke)) * 100
cbind(freq=table(data_prep2$stroke), percentage=percentage)
# Conversion des variables catégorielles en facteurs
data_prep2[] <- lapply(data_prep2, function(x) if(is.character(x)) as.factor(x) else x)
formula <- as.formula(paste("~ ."))
# Utiliser dummyVars pour créer un modèle d'encodage
dummy_model <- dummyVars(formula, data = data_prep2)
# Appliquer le modèle d'encodage pour transformer les données
data_encoded <- predict(dummy_model, newdata = data_prep2)
# Convertir le résultat en data frame
data_encoded <- as.data.frame(data_encoded)
# Ajouter la variable cible au data frame encodé
data_encoded$stroke <- data_prep2$stroke
data_encoded
# rééquilibrer les données
data_smote <- SMOTE(data_encoded[ , -ncol(data_encoded)], data_encoded$stroke, K = 5, dup_size = 12)
str(data_smote)
# Combinaison des données SMOTE générées avec les classes
data_balanced <- data_smote$data
data_balanced$class <- as.factor(data_smote$data$class)
# Vérification de la distribution des classes après rééquilibrage
table(data_balanced$class)
print(head(data_balanced))
# resumé de la distribution des classes après rééquilibrage
percentage <- prop.table(table(data_balanced$class)) * 100
cbind(freq=table(data_balanced$class), percentage=percentage)
data_split <-initial_split(data_balanced,
prop = 3/4)
data_split
data_train <- training(data_split)
data_test <- testing(data_split)
data_cv <- vfold_cv(data_train)
rf_model <-
rand_forest() %>%
set_args(mtry = tune()) %>%
set_engine("ranger", importance = "impurity") %>%
set_mode("classification")
lr_model <- logistic_reg() %>%
set_args(penalty = tune()) %>%
set_engine("glm") %>%
set_mode("classification")
nb_model <-
naive_Bayes()%>%
set_args(smoothness = tune(), Laplace = tune())%>%
set_engine("naivebayes")%>%
set_mode("classification")
svm_model <-
svm_linear() %>%
set_args(cost= tune())%>%
set_engine("kernlab") %>%
set_mode("classification")
#SVM avec noyau radial
svm_model_rbf <-
svm_rbf()%>%
set_args(cost = tune(), rbf_sigma = tune())%>%
set_engine("kernlab") %>%
set_mode("classification")
params <- parameters(lr_model)
params2 <- parameters(svm_model)
params3 <-parameters(svm_model_rbf)
rf_grid <- grid_random(mtry(range = c(1,10)),size = 10)
lr_grid <- grid_random(params,size = 10)
#definition des parametres
params <- parameters(lr_model)
params2 <- parameters(svm_model)
params3 <-parameters(svm_model_rbf)
#definir les grilles de paramettres
rf_grid <- grid_random(mtry(range = c(1,10)),size = 10)
#lr_grid <- grid_random(params,size = 10)
nb_grid <- grid_random(smoothness(range = c(0, 1)),Laplace(range = c(0, 1)), size = 10)
svm_grid <- grid_random(params2, size = 10)
svm_rbf_grid <- grid_random(params3, size = 10)
install.packages(discrim)
library(discrim)
rf_workflow <- workflow()%>%
add_model(rf_model)%>%
add_formula(class ~ .)
#add_recipe(stroke_recipe)
lr_workflow <- workflow()%>%
add_model(lr_model)%>%
add_formula(class ~ .)
#add_recipe(stroke_recipe)
nb_workflow <- workflow()%>%
add_model(nb_model)%>%
add_formula(class ~ .)
#add_recipe(stroke_recipe)
svm_workflow <- workflow()%>%
add_model(svm_model)%>%
add_formula(class ~ .)
#add_recipe(stroke_recipe)
svm_rbf_workflow <- workflow()%>%
add_model(svm_model_rbf)%>%
add_formula(class ~ .)
#add_recipe(stroke_recipe)
set.seed(123)
data_folds <-vfold_cv(data_balanced, v = 5)
print(data_folds$splits[[1]])
# Définir les métriques
metrics <- metric_set(accuracy, roc_auc, sens, f_meas)
#rechercher les hyperparamettre
rf_tune_results <- rf_workflow%>%
tune_grid( resamples = data_folds,grid = rf_grid,
metrics = metrics)
#lr_results <-lr_workflow%>%
# tune_grid(resamples = data_folds, grid = lr_grid,
#           metrics = metrics)
nb_results <-nb_workflow%>%
tune_grid(resamples = data_folds, grid = nb_grid,
metrics = metrics)
svm_results <-svm_workflow%>%
tune_grid(resamples = data_folds, grid = svm_grid,
metrics = metrics)
svm_rbf_results <-svm_rbf_workflow%>%
tune_grid(resamples = data_folds, grid = svm_rbf_grid,
metrics = metrics)
#collecte des metriques de nos modeles
rf_tune_results%>% collect_metrics()
#lr_results%>% collect_metrics()
nb_results %>% collect_metrics()
svm_results %>% collect_metrics()
svm_rbf_results %>% collect_metrics()
# Ajouter une colonne pour identifier chaque modèle
rf_tune_results <- rf_tune_results %>% mutate(model = "Random Forest")
#lr_results <- lr_results %>% mutate(model = "Logistic Regression")
nb_results <- nb_results %>% mutate(model = "Naive Bayes")
svm_results <- svm_results%>% mutate(model= "SVM")
svm_rbf_results <- svm_rbf_results%>%mutate(model = "SVM_RBF")
# Combiner les résultats
all_results <- bind_rows(rf_tune_results, nb_results,svm_results,svm_rbf_results)
all_results
# Sélectionner les meilleurs hyperparamètres pour chaque modèle
best_rf <- rf_tune_results%>%select_best(metric = "accuracy")
#best_lr <- lr_results%>%select_best(metric = "accuracy")
best_nb <- nb_results%>%select_best(metric = "accuracy")
best_svm <- svm_results%>%select_best(metric = "accuracy")
best_svm_rbf <- svm_rbf_results%>%select_best(metric = "accuracy")
# Finaliser les flux de travail
workflow_rf_final <- rf_workflow %>%
finalize_workflow(best_rf)
#workflow_lr_final <- lr_workflow %>%
# finalize_workflow(best_lr)
workflow_nb_final <- nb_workflow %>%
finalize_workflow(best_nb)
workflow_svm_final <- svm_workflow %>%
finalize_workflow(best_svm)
workflow_svm_rbf_final <- svm_rbf_workflow %>%
finalize_workflow(best_svm_rbf)
# Ajuster les modèles finaux avec les meilleurs paramètres
final_fit_rf <- fit(workflow_rf_final, data = data_train)
#final_fit_lr <- fit(workflow_lr_final, data = data_train)
final_fit_nb <- fit(workflow_nb_final, data = data_train)
final_fit_svm <- fit(workflow_svm_final, data = data_train)
final_fit_svm_rbf <- fit(workflow_svm_rbf_final, data = data_train)
# Prédictions
pred_rf <- predict(final_fit_rf, data_test) %>%
bind_cols(data_test) %>%
bind_cols(predict(final_fit_rf, data_test, type = "prob"))
pred_nb <- predict(final_fit_nb, data_test) %>%
bind_cols(data_test) %>%
bind_cols(predict(final_fit_nb, data_test, type = "prob"))
pred_svm <- predict(final_fit_svm, data_test) %>%
bind_cols(data_test) %>%
bind_cols(predict(final_fit_svm, data_test, type = "prob"))
pred_svm_rbf <- predict(final_fit_svm_rbf, data_test) %>%
bind_cols(data_test) %>%
bind_cols(predict(final_fit_svm_rbf, data_test, type = "prob"))
# Calculer les métriques pour chaque modèle
metrics_rf <- metrics(pred_rf,truth = class, estimate = .pred_class, .pred_1)
metrics_nb <- metrics(pred_nb, truth = class, estimate = .pred_class, .pred_1)
metrics_svm <- metrics(pred_svm, truth = class, estimate = .pred_class, .pred_1)
metrics_svm_rbf <- metrics(pred_svm_rbf, truth = class, estimate = .pred_class, .pred_1)
#combinaison pour comparaison
combined_metrics <- bind_rows(
metrics_rf %>% mutate(model = "Random Forest"),
metrics_nb %>% mutate(model = "Naives Bayes"),
metrics_svm %>% mutate(model = "SVM"),
metrics_svm_rbf %>% mutate(model = "SVM_RBF")
)
print(combined_metrics)
#choisir le meilleur model en fonction des metriques
# Trouver le modèle avec le meilleur F1-score
best_f1_model <- combined_metrics %>%
filter(.metric == "f_meas") %>%
arrange(desc(.estimate)) %>%
slice(1)
# Trouver le modèle avec la meilleure accuracy
best_acc_model <- combined_metrics %>%
filter(.metric == "accuracy") %>%
arrange(desc(.estimate)) %>%
slice(1)
# Afficher les résultats
print(best_f1_model)
print(best_acc_model)
#visualisation
ggplot(combined_metrics, aes(x = model, y = .estimate, fill = .metric)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Comparaison_Performances_Modeles",
y = "Valeur_metrique",
x = "Modele")
install.packages("vetiver")
install.packages("devtools")
devtools::install_github("tidymodels/vetiver-r")
library(vetiver)
install.packages("plumber")
library(plumber)
v <- vetiver_model(final_fit_rf, "Random Forest")
v
# Créer un endpoint avec plumber
#* @post /predict
#* @param input Le texte d'entrée pour les prédictions
predict_function <- function(req) {
# recueillir les données depuis le corps de la requête
data <- jsonlite::fromJSON(req$postBody)
# prédiction avec le modèle
prediction <- vetiver_predict(v, data)
# Retourne la prédiction
return(prediction)
}
pr <- plumb("C:/Users/Degbey Kayeon/Downloads/zWTIOyzKTSG0w5jU5Io_Nw_15c1635f70334a3a9d4b1ec2132e14f1_stroke-prediction/api.R") # Spécifiez le chemin vers le fichier api.R
pr$run(port = 8000)
v <- vetiver_model(final_fit_rf, "Random Forest")
v
# Créer un endpoint avec plumber
#* @post /predict
#* @param input Le texte d'entrée pour les prédictions
predict_function <- function(req) {
# recueillir les données depuis le corps de la requête
data <- fromJSON(req$postBody)
# prédiction avec le modèle
prediction <- vetiver_predict(v, data)
# Retourne la prédiction
return(prediction)
}
pr <- plumb$new()
v <- vetiver_model(final_fit_rf, "Random Forest")
v
# Créer un endpoint avec plumber
#* @post /predict
#* @param input Le texte d'entrée pour les prédictions
predict_function <- function(req) {
# recueillir les données depuis le corps de la requête
data <- fromJSON(req$postBody)
# prédiction avec le modèle
prediction <- vetiver_predict(v, data)
# Retourne la prédiction
return(prediction)
}
pr <- plumber$new()
pr$handle("POST", "/predict", function(req){
# Récupérer les données depuis le corps de la requête
data <- fromJSON(req$postBody)
# Effectuer la prédiction avec le modèle
prediction <- vetiver_predict(v, data)
# Retourner la prédiction
return(prediction)
})
pr$run(port = 8000)
v <- vetiver_model(final_fit_rf, "Random Forest")
v
# Créer un endpoint avec plumber
#* @post /predict
#* @param input Le texte d'entrée pour les prédictions
predict_function <- function(req) {
# recueillir les données depuis le corps de la requête
data <- jsonlite::fromJSON(req$postBody)
# prédiction avec le modèle
prediction <- vetiver_predict(v, data)
# Retourne la prédiction
return(prediction)
}
pr <- plumber$new()
pr$handle("POST", "/predict", function(req){
# Récupérer les données depuis le corps de la requête
data <- fromJSON(req$postBody)
# Effectuer la prédiction avec le modèle
prediction <- vetiver_predict(v, data)
# Retourner la prédiction
return(prediction)
})
pr$run(port = 8000)
v <- vetiver_model(final_fit_rf, "Random Forest")
v
# Créer un endpoint avec plumber
#* @post /predict
#* @param input Le texte d'entrée pour les prédictions
predict_function <- function(req) {
# recueillir les données depuis le corps de la requête
data <- jsonlite::fromJSON(req$postBody)
# prédiction avec le modèle
prediction <- vetiver_predict(v, data)
# Retourne la prédiction
return(prediction)
}
pr <- plumber$new()
pr$handle("POST", "/predict", function(req){
# Récupérer les données depuis le corps de la requête
data <- jsonlite::fromJSON(req$postBody)
# Effectuer la prédiction avec le modèle
prediction <- vetiver_predict(v, data)
# Retourner la prédiction
return(prediction)
})
pr$run(port = 8000)
v <- vetiver_model(final_fit_rf, "Random Forest")
v
# Créer un endpoint avec plumber
#* @post /predict
#* @param input Le texte d'entrée pour les prédictions
predict_function <- function(req) {
# recueillir les données depuis le corps de la requête
data <- jsonlite::fromJSON(req$postBody)
# prédiction avec le modèle
prediction <- vetiver_predict(v, data)
# Retourne la prédiction
return(prediction)
}
pr <- plumb("C:/Users/Degbey Kayeon/Downloads/zWTIOyzKTSG0w5jU5Io_Nw_15c1635f70334a3a9d4b1ec2132e14f1_stroke-prediction/api.R") # Spécifiez le chemin vers le fichier api.R
pr$run(port = 8000)
v <- vetiver_model(final_fit_rf, "Random Forest")
v
# Créer un endpoint avec plumber
#* @post /predict
#* @param input Le texte d'entrée pour les prédictions
predict_function <- function(req) {
cat("Requête reçue :", req$postBody, "\n")
# recueillir les données depuis le corps de la requête
data <- tryCatch(
jsonlite::fromJSON(req$postBody),
error = function(e){
cat("Erreur de parsing JSON:", e$message, "\n")
stop("Invalid JSON format")
}
)
# prédiction avec le modèle
prediction <- vetiver_predict(v, data)
# Retourne la prédiction
return(prediction)
}
pr <- plumb("C:/Users/Degbey Kayeon/Downloads/zWTIOyzKTSG0w5jU5Io_Nw_15c1635f70334a3a9d4b1ec2132e14f1_stroke-prediction/api.R") # Spécifiez le chemin vers le fichier api.R
pr$run(port = 8000)
v <- vetiver_model(final_fit_rf, "Random Forest")
v
# Créer un endpoint avec plumber
#* @post /predict
#* @param input Le texte d'entrée pour les prédictions
predict_function <- function(req) {
cat("Requête reçue :", req$postBody, "\n")
# recueillir les données depuis le corps de la requête
data <- tryCatch(
jsonlite::fromJSON(req$postBody),
error = function(e){
cat("Erreur de parsing JSON:", e$message, "\n")
stop("Invalid JSON format")
}
)
# prédiction avec le modèle
prediction <- vetiver_predict(v, data)
# Retourne la prédiction
return(prediction)
}
pr <- plumb("C:/Users/Degbey Kayeon/Downloads/zWTIOyzKTSG0w5jU5Io_Nw_15c1635f70334a3a9d4b1ec2132e14f1_stroke-prediction/api.R") # Spécifiez le chemin vers le fichier api.R
pr$run(port = 8000)
v <- vetiver_model(final_fit_rf, "Random Forest")
v
# Créer un endpoint avec plumber
#* @post /predict
#* @param input Le texte d'entrée pour les prédictions
predict_function <- function(req) {
cat("Requête reçue :", req$postBody, "\n")
# recueillir les données depuis le corps de la requête
data <- tryCatch(
jsonlite::fromJSON(req$postBody),
error = function(e){
cat("Erreur de parsing JSON:", e$message, "\n")
stop("Invalid JSON format")
}
)
# prédiction avec le modèle
prediction <- vetiver_predict(v, data)
# Retourne la prédiction
return(prediction)
}
pr <- plumb("C:/Users/Degbey Kayeon/Downloads/zWTIOyzKTSG0w5jU5Io_Nw_15c1635f70334a3a9d4b1ec2132e14f1_stroke-prediction/api.R") # Spécifiez le chemin vers le fichier api.R
pr$run(port = 8000)
